# London Bike Sharing Demand Prediction with LSTM (PyTorch)

æœ¬é¡¹ç›®åŸºäº Kaggle å¼€æºçš„ **London Bike Sharing Dataset**ï¼Œä½¿ç”¨ PyTorch å®ç° LSTM å¾ªç¯ç¥ç»ç½‘ç»œæ¥é¢„æµ‹æœªæ¥è‹¥å¹²å°æ—¶å…±äº«å•è½¦çš„ç§Ÿå€Ÿéœ€æ±‚ã€‚

## ç›®å½•ç»“æ„

```text
.
â”œâ”€â”€ data/                   # åŸå§‹åŠå¤„ç†åçš„æ•°æ®
â”œâ”€â”€ notebooks/              # äº¤äº’å¼æ¢ç´¢åˆ†æ
â”œâ”€â”€ outputs/                # è®­ç»ƒæ—¥å¿—ã€æ¨¡å‹æƒé‡ã€ç»“æœå›¾è¡¨
â”œâ”€â”€ src/                    # ä¸»è¦æºä»£ç 
â”‚   â”œâ”€â”€ dataset.py          # æ•°æ®åŠ è½½ä¸æ»‘çª— Dataset
â”‚   â”œâ”€â”€ model.py            # LSTM ç½‘ç»œç»“æ„
â”‚   â”œâ”€â”€ train.py            # è®­ç»ƒå…¥å£è„šæœ¬
â”‚   â””â”€â”€ utils.py            # å·¥å…·å‡½æ•°
â”œâ”€â”€ requirements.txt        # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md               # å½“å‰æ–‡æ¡£
```

## å¿«é€Ÿå¼€å§‹

1. å…‹éš†ä»“åº“å¹¶å®‰è£…ä¾èµ–ï¼š

```bash
pip install -r requirements.txt
```

2. ä¸‹è½½æ•°æ®é›†ï¼ˆçº¦ 1.3MBï¼‰ï¼š

```bash
mkdir -p data/raw && 
wget -O data/raw/london_merged.csv \
  https://raw.githubusercontent.com/hmavrodiev/london-bike-sharing-dataset/master/london_merged.csv
```

3. è®­ç»ƒæ¨¡å‹ï¼š

```bash
python src/train.py \
  --data-path data/raw/london_merged.csv \
  --epochs 30 \
  --pred-horizon 6 \
  --save-dir outputs
```

é»˜è®¤ä½¿ç”¨ CPUï¼›å¦‚éœ€ GPUï¼Œè¯·ç¡®ä¿æ­£ç¡®å®‰è£…äº† CUDA ç‰ˆæœ¬çš„ PyTorchï¼Œå¹¶åœ¨è¿è¡Œæ—¶ä¼ å…¥ `--device cuda`ã€‚

4. è®­ç»ƒå®Œæˆåï¼Œå¯åœ¨ `outputs/` æŸ¥çœ‹ï¼š

* `model_best.pt` â€” éªŒè¯é›†è¡¨ç°æœ€ä½³çš„æ¨¡å‹æƒé‡
* `loss_curve.png` â€” è®­ç»ƒ/éªŒè¯æŸå¤±æ›²çº¿
* `prediction_plot.png` â€” åœ¨æµ‹è¯•é›†ä¸Šçš„çœŸå® vs. é¢„æµ‹æ›²çº¿

## ä¸¤ç§å»ºæ¨¡åœºæ™¯

### 1. é¢„æµ‹ä¸‹ä¸€ä¸ªå°æ—¶ï¼ˆå•æ­¥é¢„æµ‹ï¼‰

- è®­ç»ƒæŒ‡ä»¤ï¼š
  ```bash
  python src/train.py \
    --data-path data/raw/london_merged.csv \
    --pred-horizon 1 \
    --epochs 30 \
    --save-dir outputs/1h
  ```
- è¯„ä¼°æŒ‡æ ‡å°†ä»…å¯¹ `t+1` çš„ç§Ÿå€Ÿé‡è¿›è¡Œè®¡ç®—ã€‚
- éƒ¨ç½²æ—¶åœ¨ Streamlit ä¾§è¾¹æ é€‰æ‹© `Prediction horizon = 1` å¹¶å°†æ¨¡å‹è·¯å¾„æ”¹ä¸º `outputs/1h/model_best.pt`ã€‚

### 2. é¢„æµ‹æœªæ¥ 6 å°æ—¶ï¼ˆå¤šæ­¥é¢„æµ‹ï¼‰

- è®­ç»ƒæŒ‡ä»¤ï¼š
  ```bash
  python src/train.py \
    --data-path data/raw/london_merged.csv \
    --pred-horizon 6 \
    --epochs 30 \
    --save-dir outputs/6h
  ```
- æ¨¡å‹è¾“å‡ºä¸ºä¸€ä¸ªé•¿åº¦ 6 çš„å‘é‡ï¼Œåˆ†åˆ«å¯¹åº” `t+1 ... t+6`ã€‚
- éƒ¨ç½²æ—¶åœ¨ Streamlit é€‰æ‹© `Prediction horizon = 6` å¹¶åˆ‡æ¢æ¨¡å‹è·¯å¾„ã€‚

---

## éƒ¨ç½²ä¸å¯è§†åŒ–

å®‰è£…é¢å¤–ä¾èµ–ï¼š
```bash
pip install streamlit
```
è¿è¡Œåº”ç”¨ï¼š
```bash
streamlit run src/app.py --server.port 8501
```
ç„¶ååœ¨æµè§ˆå™¨æ‰“å¼€ `http://localhost:8501` å³å¯ï¼š

1. ä¾§è¾¹æ é…ç½®æ¨¡å‹æƒé‡ã€Scalerã€æ•°æ®é›†è·¯å¾„ä»¥åŠé¢„æµ‹æ­¥é•¿ã€‚
2. æ‹–åŠ¨æ»‘å—æŸ¥çœ‹ä¸åŒæ ·æœ¬çš„ **çœŸå® vs é¢„æµ‹** å¯¹æ¯”æ›²çº¿ä¸ RMSE/MAE æŒ‡æ ‡ã€‚
3. é¡µé¢ä¸‹æ–¹å±•ç¤º LSTM ç½‘ç»œç»“æ„æ–‡æœ¬æ‘˜è¦ã€‚

![](docs/screenshot.png)

> ç”Ÿäº§ç¯å¢ƒå¯å°† Streamlit éƒ¨ç½²åˆ°äº‘æœåŠ¡å™¨æˆ–å°è£…ä¸º Docker é•œåƒã€‚

## éƒ¨ç½²ç¤ºä¾‹

ç»è¿‡è®­ç»ƒçš„æ¨¡å‹å¯è½»æ¾é›†æˆè¿›åç«¯æˆ– Web åº”ç”¨ã€‚ç¤ºä¾‹ï¼š

```python
from src.model import LSTMBikePredictor
import torch, joblib, pandas as pd

model = LSTMBikePredictor(input_dim=10, hidden_dim=64, num_layers=2, output_dim=6)
model.load_state_dict(torch.load("outputs/model_best.pt", map_location="cpu"))
model.eval()

scaler = joblib.load("outputs/feature_scaler.pkl")

# å‡è®¾ `latest_df` ä¸ºæœ€è¿‘ 24 å°æ—¶å·²å¤„ç†å¥½ç‰¹å¾çš„ DataFrame
x = torch.tensor(scaler.transform(latest_df.values), dtype=torch.float32).unsqueeze(0)
with torch.no_grad():
    preds = model(x)
print(preds)
```

## ONNX éƒ¨ç½²ï¼ˆFastAPI + ONNX Runtimeï¼‰

ä¸ºäº†åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è·å¾—æ›´é«˜çš„æ¨ç†æ€§èƒ½å¹¶ä¸è¯­è¨€æ— å…³ï¼Œæœ¬é¡¹ç›®æä¾›äº† **ONNX å¯¼å‡ºä¸æ¨ç† API** ç¤ºä¾‹ï¼Œç»“åˆ FastAPI & onnxruntime è½»é‡çº§ä¸Šçº¿ã€‚

1. **å¯¼å‡ºæ¨¡å‹è‡³ ONNX**ï¼ˆå‡è®¾å·²å®Œæˆæ¨¡å‹è®­ç»ƒå¹¶å¾—åˆ° `model_best.pt`ï¼‰ï¼š

   ```bash
   python deploy/convert_to_onnx.py \
     --model-path outputs/model_best.pt \
     --onnx-path outputs/model_best.onnx \
     --input-dim 13 --window-size 24 --pred-horizon 6
   ```

   è¿è¡Œå®Œæˆåå°†åœ¨ `outputs/` ç”Ÿæˆ `model_best.onnx` æ–‡ä»¶ã€‚

2. **å®‰è£…æ¨ç†ä¾èµ–**ï¼ˆè‹¥å·²æŒ‰ `requirements.txt` å…¨é‡å®‰è£…ï¼Œå¯è·³è¿‡ï¼‰ï¼š

   ```bash
   pip install onnxruntime fastapi uvicorn[standard]
   ```

3. **å¯åŠ¨ FastAPI æ¨ç†æœåŠ¡**ï¼ˆé»˜è®¤ä¸º CPUï¼Œå¯æ ¹æ®ç¯å¢ƒä¿®æ”¹ `providers` åˆ—è¡¨ä»¥å¯ç”¨ CUDA / TensorRT ç­‰ï¼‰ï¼š

   ```bash
   python -m uvicorn deploy.onnx_server:app --host 0.0.0.0 --port 8000
   ```

   æœåŠ¡å¯åŠ¨åï¼Œå¯é€šè¿‡ `POST /predict` å‘é€å½¢çŠ¶ä¸º `(WINDOW_SIZE, INPUT_DIM)` çš„äºŒç»´åˆ—è¡¨ï¼ˆJSONï¼‰è·å¾—é¢„æµ‹ç»“æœï¼š

   ```json
   {
     "data": [[0.42, 0.13, ...], [...], ...]
   }
   ```

   è¿”å›ï¼š

   ```json
   { "prediction": [0.21, 0.19, ...] }
   ```

4. **åœ¨ Streamlit å‰ç«¯æ¥å…¥è¿œç¨‹æ¨ç†**ï¼š

   æ‰“å¼€ `src/app.py` å¯¹åº”çš„ Streamlit åº”ç”¨ï¼Œåœ¨ä¾§è¾¹æ çš„ **Inference API URL** è¾“å…¥è¿è¡Œä¸­çš„ FastAPI åœ°å€ï¼ˆå¦‚ `http://localhost:8000`ï¼‰ï¼Œå³å¯å®æ—¶è°ƒç”¨ ONNX æœåŠ¡å¹¶å±•ç¤ºé¢„æµ‹ç»“æœã€‚

> å¦‚éœ€éƒ¨ç½²åˆ°å®¹å™¨æˆ–äº‘ç¯å¢ƒï¼Œå¯å°† `deploy/onnx_server.py` æ‰“åŒ…ä¸º Docker é•œåƒï¼Œæˆ–æŒ‚è½½ NGINX / Traefik è¿›è¡Œåå‘ä»£ç†ä¸è´Ÿè½½å‡è¡¡ã€‚

---

## å‚è€ƒæ–‡çŒ®

* [London Bike Sharing Dataset on Kaggle](https://www.kaggle.com/datasets/hmavrodiev/london-bike-sharing-dataset)
* æ·±åº¦å­¦ä¹ ä¸æ—¶é—´åºåˆ—é¢„æµ‹ç›¸å…³ä¹¦ç±/è®ºæ–‡

---

å¦‚æœ‰é—®é¢˜æˆ–æ”¹è¿›å»ºè®®ï¼Œæ¬¢è¿æ issue æˆ– PR ğŸ™Œ