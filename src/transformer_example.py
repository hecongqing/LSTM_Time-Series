#!/usr/bin/env python3
"""
Transformeræ¨¡å‹ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•è®­ç»ƒå’Œä½¿ç”¨Transformerè¿›è¡Œæ—¶é—´åºåˆ—é¢„æµ‹
"""

import sys
import os
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).resolve().parent))

def train_transformer_model():
    """è®­ç»ƒTransformeræ¨¡å‹ç¤ºä¾‹"""
    print("=" * 60)
    print("è®­ç»ƒTransformeræ¨¡å‹")
    print("=" * 60)
    
    # å¯¼å…¥è®­ç»ƒå‡½æ•°
    from transformer_train import train_model, parse_args
    
    # æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°
    class Args:
        def __init__(self):
            self.data_path = "data/raw/london_merged.csv"  # è¯·æ›¿æ¢ä¸ºå®é™…æ•°æ®è·¯å¾„
            self.epochs = 30
            self.batch_size = 64
            self.lr = 3e-4
            self.window_size = 24
            self.pred_horizon = 6
            self.embed_size = 256
            self.num_heads = 8
            self.num_blocks = 2
            self.dropout = 0.1
            self.device = "cpu"
            self.save_dir = "transformer_outputs"
            self.use_categorical = False  # å…ˆä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
            self.loss_type = "mse"
            self.time_shuffle = False
    
    args = Args()
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.data_path).exists():
        print(f"é”™è¯¯: æ•°æ®æ–‡ä»¶ {args.data_path} ä¸å­˜åœ¨")
        print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶è·¯å¾„æ­£ç¡®")
        return False
    
    try:
        print(f"å¼€å§‹è®­ç»ƒTransformeræ¨¡å‹...")
        print(f"æ•°æ®è·¯å¾„: {args.data_path}")
        print(f"è¾“å‡ºç›®å½•: {args.save_dir}")
        print(f"ä½¿ç”¨åˆ†ç±»ç‰¹å¾: {args.use_categorical}")
        print(f"çª—å£å¤§å°: {args.window_size}, é¢„æµ‹æ­¥é•¿: {args.pred_horizon}")
        print(f"æ¨¡å‹å‚æ•°: embed_size={args.embed_size}, num_heads={args.num_heads}, num_blocks={args.num_blocks}")
        print()
        
        train_model(args)
        print("\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"æ¨¡å‹æ–‡ä»¶ä¿å­˜åœ¨: {args.save_dir}/")
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False


def run_transformer_inference():
    """è¿è¡ŒTransformeræ¨ç†ç¤ºä¾‹"""
    print("=" * 60)
    print("Transformeræ¨¡å‹æ¨ç†")
    print("=" * 60)
    
    import torch
    import joblib
    import numpy as np
    from transformer_dataset import TransformerBikeDataset, create_features_transformer
    from transformer_model import SimplifiedTransformerBikePredictor, TransformerBikePredictor
    import pandas as pd
    
    # æ¨¡å‹è·¯å¾„
    model_path = "transformer_outputs/transformer_model_best.pt"
    scaler_path = "transformer_outputs/transformer_feature_scaler.pkl"
    config_path = "transformer_outputs/transformer_model_config.pkl"
    data_path = "data/raw/london_merged.csv"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    required_files = [model_path, scaler_path, config_path, data_path]
    for file_path in required_files:
        if not Path(file_path).exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            print("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡å‹æ–‡ä»¶")
            return False
    
    try:
        # åŠ è½½é…ç½®å’Œé¢„å¤„ç†å™¨
        config = joblib.load(config_path)
        scaler = joblib.load(scaler_path)
        
        print(f"âœ… åŠ è½½æ¨¡å‹é…ç½®: {config['model_type']} æ¨¡å‹")
        print(f"   - åµŒå…¥ç»´åº¦: {config['embed_size']}")
        print(f"   - æ³¨æ„åŠ›å¤´æ•°: {config['num_heads']}")
        print(f"   - Transformerå—æ•°: {config['num_blocks']}")
        
        # åŠ è½½æ¨¡å‹
        if config['model_type'] == 'simplified':
            model = SimplifiedTransformerBikePredictor(
                input_dim=config['num_numeric_features'],
                embed_size=config['embed_size'],
                num_heads=config['num_heads'],
                num_blocks=config['num_blocks'],
                output_dim=config['output_dim'],
                dropout=config['dropout'],
            )
        else:
            model = TransformerBikePredictor(
                numeric_features=config['num_numeric_features'],
                categorical_features_dims=config['categorical_dims'],
                static_features_dims=config['static_dims'],
                embed_size=config['embed_size'],
                num_heads=config['num_heads'],
                num_blocks=config['num_blocks'],
                output_dim=config['output_dim'],
                dropout=config['dropout'],
            )
        
        model.load_state_dict(torch.load(model_path, map_location='cpu'))
        model.eval()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # åŠ è½½æ•°æ®
        df = pd.read_csv(data_path)
        df = create_features_transformer(df)
        
        # å‡†å¤‡ç‰¹å¾
        numeric_cols = [
            "cnt", "t1", "t2", "hum", "wind_speed",
            "hour_sin", "hour_cos", "month_sin", "month_cos",
            "dayofweek_sin", "dayofweek_cos",
        ]
        
        numeric_data = df[numeric_cols].values
        numeric_scaled = scaler.transform(numeric_data)
        
        # åˆ›å»ºæ•°æ®é›†
        window_size = 24
        pred_horizon = 6
        ds = TransformerBikeDataset(
            numeric_scaled, None, None, window_size, pred_horizon
        )
        
        print(f"âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆ: {len(ds)} ä¸ªæ ·æœ¬")
        
        # è¿›è¡Œæ¨ç†
        test_idx = len(ds) - 100  # ä½¿ç”¨å€’æ•°ç¬¬100ä¸ªæ ·æœ¬
        x_numeric, x_categorical, x_static, y_true = ds[test_idx]
        
        with torch.no_grad():
            x_batch = x_numeric.unsqueeze(0)
            
            if config['model_type'] == 'simplified':
                y_pred = model(x_batch).numpy().flatten()
            else:
                y_pred = model(x_batch, None, None).numpy().flatten()
        
        y_true = y_true.numpy()[:pred_horizon]
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        rmse = np.sqrt(np.mean((y_pred - y_true) ** 2))
        mae = np.mean(np.abs(y_pred - y_true))
        
        print("\n" + "=" * 40)
        print("é¢„æµ‹ç»“æœ")
        print("=" * 40)
        print(f"RMSE: {rmse:.4f}")
        print(f"MAE:  {mae:.4f}")
        print()
        print("é€å°æ—¶é¢„æµ‹å¯¹æ¯”:")
        print("å°æ—¶\tçœŸå®å€¼\té¢„æµ‹å€¼\tç»å¯¹è¯¯å·®")
        print("-" * 40)
        for i in range(pred_horizon):
            error = abs(y_true[i] - y_pred[i])
            print(f"{i+1:2d}\t{y_true[i]:.4f}\t{y_pred[i]:.4f}\t{error:.4f}")
        
        print("\nâœ… æ¨ç†å®Œæˆ!")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– Transformeræ—¶é—´åºåˆ—é¢„æµ‹ç¤ºä¾‹")
    print("æœ¬ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨Transformerè¿›è¡Œä¼¦æ•¦è‡ªè¡Œè½¦éœ€æ±‚é¢„æµ‹")
    print()
    
    while True:
        print("è¯·é€‰æ‹©æ“ä½œ:")
        print("1. è®­ç»ƒTransformeræ¨¡å‹")
        print("2. è¿è¡Œæ¨¡å‹æ¨ç†")
        print("3. å¯åŠ¨Streamlitåº”ç”¨")
        print("4. é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
        
        if choice == "1":
            success = train_transformer_model()
            if success:
                print("\nå¯ä»¥é€‰æ‹©é€‰é¡¹2è¿›è¡Œæ¨ç†æµ‹è¯•ï¼Œæˆ–é€‰æ‹©é€‰é¡¹3å¯åŠ¨Webåº”ç”¨")
        
        elif choice == "2":
            run_transformer_inference()
            
        elif choice == "3":
            print("\nå¯åŠ¨Streamlitåº”ç”¨...")
            print("è¿è¡Œä»¥ä¸‹å‘½ä»¤:")
            print("cd src && streamlit run transformer_app.py")
            break
            
        elif choice == "4":
            print("å†è§!")
            break
            
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        
        print("\n" + "="*60 + "\n")


if __name__ == "__main__":
    main()